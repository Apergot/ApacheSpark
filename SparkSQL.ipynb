{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL and Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to import SQLContext module, which is needed to access SQL databases in Spark. Then we need to create a context instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlsc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a Spark DataFrame for a table from our PostgreSQL DB, the source of the DataFrame will be using a Java Database Connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- clickid: integer (nullable = false)\n",
      " |-- userid: integer (nullable = false)\n",
      " |-- usersessionid: integer (nullable = false)\n",
      " |-- ishit: integer (nullable = false)\n",
      " |-- teamid: integer (nullable = false)\n",
      " |-- teamlevel: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlsc.read.format(\"jdbc\")\\\n",
    ".option(\"url\", \"jdbc:postgresql://localhost/cloudera?user=cloudera\")\\\n",
    ".option(\"dbtable\", \"gameclicks\")\\\n",
    ".load()\n",
    "\n",
    "#Checking if the schema was correctly loaded\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755806"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can count the registers in the DataFrame by calling the count() method\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+\n",
      "|userid|teamlevel|teamid|\n",
      "+------+---------+------+\n",
      "|  1038|        1|    25|\n",
      "|  1099|        1|    44|\n",
      "|   899|        1|    71|\n",
      "|  2197|        1|    99|\n",
      "|  1362|        1|    13|\n",
      "+------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we can also filter one or more columns by calling the select() method\n",
    "df.select(\"userid\", \"teamlevel\", \"teamid\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter rows based on criteria\n",
    "\n",
    "We can also filter for rows that match a specific criteria using **filter()** method. In the following example we would like to display the userid and the teamlevel for those players whose teamlevel is greater than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|userid|teamlevel|\n",
      "+------+---------+\n",
      "|  1513|        2|\n",
      "|   868|        2|\n",
      "|  1453|        2|\n",
      "|  1282|        2|\n",
      "|  1473|        2|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"teamlevel\"]>1).select(\"userid\",\"teamlevel\").show(5)\n",
    "\n",
    "#we can also use head(n) and tail(n) to retrieve registers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by a column and count\n",
    "\n",
    "The **groupBy()** method groups the value of columns. In this example table there is one column which only has values 0 and 1, we can calculate how many time each occurs by grouping the values of this register and counting the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ishit| count|\n",
      "+-----+------+\n",
      "|    0|672423|\n",
      "|    1| 83383|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"ishit\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate operations\n",
    "\n",
    "Aggregate operations can be performed on columns of DataFrames, but first we need to import the libraries for this aggregate operations. Once this is done, we will, for example, calculate the average and total values by calling **mean()** and **sum()** methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(ishit)|\n",
      "+------------------+\n",
      "|0.1103232840173272|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Calculating the average of ishit\n",
    "df.select(mean(\"ishit\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(ishit)|\n",
      "+----------+\n",
      "|     83383|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating sum of ishit\n",
    "df.select(sum(\"ishit\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join two dataframes\n",
    "\n",
    "We can merge or join two Dataframes on a single column. First, let's create a second Dataframe using another table with one of the columns of the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- txid: integer (nullable = false)\n",
      " |-- usersessionid: integer (nullable = false)\n",
      " |-- teamid: integer (nullable = false)\n",
      " |-- userid: integer (nullable = false)\n",
      " |-- adid: integer (nullable = false)\n",
      " |-- adcategory: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = sqlsc.read.format(\"jdbc\")\\\n",
    ".option(\"url\", \"jdbc:postgresql://localhost/cloudera?user=cloudera\")\\\n",
    ".option(\"dbtable\", \"adclicks\")\\\n",
    ".load()\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will join both Dataframes on the attribute userid by using **join()** method and saving the resulting Dataframe in a variable called merge_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- clickid: integer (nullable = false)\n",
      " |-- usersessionid: integer (nullable = false)\n",
      " |-- ishit: integer (nullable = false)\n",
      " |-- teamid: integer (nullable = false)\n",
      " |-- teamlevel: integer (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- txid: integer (nullable = false)\n",
      " |-- usersessionid: integer (nullable = false)\n",
      " |-- teamid: integer (nullable = false)\n",
      " |-- adid: integer (nullable = false)\n",
      " |-- adcategory: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merge_result = df.join(df2, 'userid')\n",
    "\n",
    "#Let's check the schema, just point out merge_result is another dataframe\n",
    "merge_result.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the resulting Dataframe has all the columns of both tables, gameclicks and adclicks. Finally we will take a look to the contents of the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------+-------------+-----+------+---------+--------------------+-----+-------------+------+----+----------+\n",
      "|userid|           timestamp|clickid|usersessionid|ishit|teamid|teamlevel|           timestamp| txid|usersessionid|teamid|adid|adcategory|\n",
      "+------+--------------------+-------+-------------+-----+------+---------+--------------------+-----+-------------+------+----+----------+\n",
      "|   231|2016-06-08 00:45:...| 376796|        23626|    0|   142|        4|2016-06-08 01:40:...|23669|        23626|   142|  27|     games|\n",
      "|   231|2016-06-08 00:45:...| 376796|        23626|    0|   142|        4|2016-06-08 09:24:...|24122|        23626|   142|   4|     games|\n",
      "|   231|2016-06-08 00:45:...| 376796|        23626|    0|   142|        4|2016-06-08 17:21:...|24659|        23626|   142|  22| computers|\n",
      "|   231|2016-06-08 00:45:...| 376796|        23626|    0|   142|        4|2016-06-08 23:34:...|25076|        23626|   142|  21|    movies|\n",
      "|   231|2016-06-08 00:45:...| 376796|        23626|    0|   142|        4|2016-06-09 16:32:...|26220|        23626|   142|  16|  clothing|\n",
      "+------+--------------------+-------+-------------+-----+------+---------+--------------------+-----+-------------+------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merge_result.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
